I built Grandma’s Car almost entirely through Google AI Studio’s vibe coding tools, starting with a simple prompt to create a used-car marketplace, like AutoTrader, but focused on reliability and transparency. I added details about my target users, the brand’s mission, and the playful color scheme. AI Studio generated the initial layout, and I iterated from there.
I manually replaced mismatched car photos using Pexels images (this was the largest UI challenge) and told the model which images corresponded to which make and model. I also instructed the system to add icons for reliability and mechanic inspection status, create a featured cars section, and add maintenance forecasting to each car page.
I also added an AI chat feature - Grandma’s Assistant - to the homepage. After prompting: “Please make the AI Buyer Assistant Chat functional,” the model connected the UI to the underlying LLM and began producing helpful recommendations. I also added an AI natural-language search bar so users could describe needs like “safe SUV under $15k,” and the system would filter options accordingly.
AI handled most of the front-end generation, tone, layout, and interactions, but I made all product decisions myself and corrected or clarified outputs as needed.
I chose two AI features because they directly solve the main user problem: buying a used car is intimidating and confusing, especially for students and budget-conscious families. Most people don’t know what model they need—they know their situation. So natural-language search helps them shop like they talk.
Grandma’s Assistant adds warmth and guidance to an otherwise stressful process. The friendly persona makes the experience feel more human and trustworthy, which fits the brand’s mission.
I intentionally avoided complex features like VIN decoding or real-time pricing because they require data sources outside the scope of this course. The two AI features I included demonstrate meaningful, user-centered value without pretending to be more sophisticated than they are.
There are several risks in using generative AI for recommendations:
Accuracy: AI can hallucinate maintenance issues or generalize reliability trends.


User overtrust: Tone can make suggestions sound authoritative even when they’re not.


Bias: The model may favor certain brands based on its training data.


Ethical claims: AI cannot guarantee a car’s condition (hence the built-in requirement for mechanic inspection and documentation).


I mitigated these by using cautious, advisory language, keeping recommendations high-level, and ensuring every listed car requires a real inspection.
From an academic integrity standpoint, AI helped generate code and content, but all ideas, product strategy, and corrections came from me.
Building with GenAI taught me that clear prompting matters more than anything. The more specific I was about brand, tone, and function, the better the output. I also learned that AI can accelerate prototyping significantly, but it still requires human judgment and constant iteration.
Most importantly, I learned how to pair AI’s strengths (speed, natural-language reasoning, classification) with human strengths (product vision, ethics, constraints). It strengthened my confidence in using AI in both entrepreneurial projects and in my full-time role, where I often explain AI’s real capabilities to others. However, I’ve discovered that, as helpful and effective as AI is, I still need additional outside guidance to take my ideas to the next level.

